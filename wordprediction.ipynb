{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fastinom/fassy/blob/main/wordprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TL10Dww38ks4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fastino Mateteva\n",
        "R205684K**"
      ],
      "metadata": {
        "id": "uFWZEGPU8d59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHHvLPffBnZ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N7Zo_UhY8ba3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DsVC2gpP8cno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIBvRBcMFwlk"
      },
      "outputs": [],
      "source": [
        " from google.colab import files\n",
        "uploaded= files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2SOzPHnHhe1"
      },
      "source": [
        "Load and Pre-process the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3AU6TZjMFRS"
      },
      "outputs": [],
      "source": [
        "file = open(\"txt.txt\", \"r\", encoding = \"utf8\")\n",
        "#store file in list\n",
        "lines =[]\n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "\n",
        "#Convert list to string \n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '.join(lines)\n",
        "#replace unneccessary stuff with space\n",
        "data = data.replace('\\n','').replace('\\ufeff','').replace('\"','').replace('\"','') #new line, carriage return, unicode character\n",
        "\n",
        "#rmove unnecessary spaces \n",
        "data = data.split()\n",
        "data =' '.join(data)\n",
        "data[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_nqJck3jsRD"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKNYiH88NUuV"
      },
      "source": [
        "Apply Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klLO8Ua5j0yG"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "#saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer,open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data]) [0]\n",
        "sequence_data[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJb8AlL5PdDS"
      },
      "outputs": [],
      "source": [
        "len(sequence_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt_ovbeCPoi_"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll7uKO1lQB_S"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(5, len(sequence_data)):\n",
        "  words = sequence_data[i-5:i+1]\n",
        "  sequences.append(words)\n",
        "\n",
        "print(\"The Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences [:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpkTGjH-RvkZ"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "for i in sequences:\n",
        "   x.append(i[0:5])\n",
        "   y.append(i[5])\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia8r698RTSWW"
      },
      "outputs": [],
      "source": [
        "print(\"Data: \", x[:10])\n",
        "print(\"Response: \", y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX0FSbH1Xgex"
      },
      "outputs": [],
      "source": [
        "\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaaA2ZqJkNZz"
      },
      "source": [
        "CREATING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rotGD5fPcUux"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "model = Sequential ()\n",
        "model.add(Embedding(vocab_size, 10, input_length=5))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYTxe5bjmcRo"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxuYR0DUMXb0"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras \n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5noUy_HJlhcv"
      },
      "source": [
        "**Building a model **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKMiMuAgc0s-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"nextword.h5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto')\n",
        "\n",
        "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
        "\n",
        "logdir='logsnextword1'\n",
        "tensorboard_Visualization = TensorBoard(log_dir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DO0mLPhV_iI"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.002), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouPar8tvWOin"
      },
      "outputs": [],
      "source": [
        "history=model.fit(x, y, epochs=75, batch_size=64, callbacks=[checkpoint, reduce, tensorboard_Visualization])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfg-DhVOIzfg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3-JVpdQmu9H"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "#model = load_model('next_words.h5')\n",
        "#tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7HbCZbpt-4h"
      },
      "outputs": [],
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-5:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cY9uPyN-xmh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}